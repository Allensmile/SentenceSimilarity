# SimilarityCompute
self complement of Sentence Similarity compute based on cilin, hownet, simhash, wordvector,vsm models，基于同义词词林，知网，指纹，字词向量，向量空间模型的句子相似度计算。
# 简介
中文句子相似度计算，目前包括word-level和sentence-level两个level的计算方法。前者的思想是通过对句子进行分词，分别计算两个比较句中所含词汇的相似度。后者主要采用句子建模的方法。  
word-level的方法包括两个核心问题，1）word之间的相似度计算问题 2)将句子中多个word相似度进行加权融合的问题。其中：  
1）word之间相似度的计算问题，分成两种，一种是形态（包括字符级的形态以及词语级的形态）上的相似，这个在英语中是比较可行的，英语中可以将词语进行词干化，而在中文中并不适用，例如‘爸爸’和‘父亲’实际上是同一个词，但是形态上的相似度是0，这显然是不行的。因此诞生了第二种方法，基于语义知识库的词语相似度计算，目前中文的语义知识库比较著名的有董振东先生研发的hownet以及哈工大研发的大词林，其中hownet将每个词的意义分解为多个义原，例如：{爸爸：human|人,family|家,male|男}，{父亲：human|人,family|家,male|男}，在cilin中，则对相似词语进行了编码，如 {Ah04A01= 父 父亲 爷 爹 大 翁 爸爸 老子 爹爹 老爹 阿爹 阿爸 椿 太公 大人 爸 生父 爹地 慈父}，可以看出‘爸爸’和‘父亲’都属于同一个语义编码。因此，借助外部语义知识库，可以在一定程度上解决中文的形态问题。但受限于知识库的词汇有限，难以大规模的适用。
2）基于word相似度的句子相似度加权问题。这里涉及基于词相似的句子相似度度量，主要常用的jaccard编辑距离，  
